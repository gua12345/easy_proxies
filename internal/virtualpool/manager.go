// Package virtualpool å®ç°è™šæ‹Ÿæ± åŠŸèƒ½
// è™šæ‹Ÿæ± å…è®¸ç”¨æˆ·é€šè¿‡æ­£åˆ™è¡¨è¾¾å¼ç­›é€‰èŠ‚ç‚¹ï¼Œåˆ›å»ºç‹¬ç«‹çš„è´Ÿè½½å‡è¡¡å…¥å£
package virtualpool

import (
	"context"
	"fmt"
	"sync"

	"easy_proxies/internal/config"
	"easy_proxies/internal/logger"
	"easy_proxies/internal/monitor"
)

// Manager è™šæ‹Ÿæ± ç®¡ç†å™¨
// è´Ÿè´£ç®¡ç†æ‰€æœ‰è™šæ‹Ÿæ± çš„ç”Ÿå‘½å‘¨æœŸ
type Manager struct {
	pools      map[string]*VirtualPool // è™šæ‹Ÿæ± æ˜ å°„è¡¨ï¼Œkey ä¸ºæ± åç§°
	monitorMgr *monitor.Manager        // èŠ‚ç‚¹ç›‘æ§ç®¡ç†å™¨
	cfg        *config.Config          // é…ç½®
	mu         sync.RWMutex
	ctx        context.Context
	cancel     context.CancelFunc
}

// NewManager åˆ›å»ºè™šæ‹Ÿæ± ç®¡ç†å™¨
func NewManager(cfg *config.Config, monitorMgr *monitor.Manager) *Manager {
	ctx, cancel := context.WithCancel(context.Background())
	return &Manager{
		pools:      make(map[string]*VirtualPool),
		monitorMgr: monitorMgr,
		cfg:        cfg,
		ctx:        ctx,
		cancel:     cancel,
	}
}

// Start å¯åŠ¨æ‰€æœ‰è™šæ‹Ÿæ± 
func (m *Manager) Start() error {
	m.mu.Lock()
	defer m.mu.Unlock()

	if len(m.cfg.VirtualPools) == 0 {
		logger.Infof("ğŸ“¦ No virtual pools configured")
		return nil
	}

	logger.Infof("ğŸ“¦ Starting %d virtual pool(s)...", len(m.cfg.VirtualPools))

	for _, poolCfg := range m.cfg.VirtualPools {
		pool, err := NewVirtualPool(m.ctx, poolCfg, m.monitorMgr, m.cfg)
		if err != nil {
			// å…³é—­å·²å¯åŠ¨çš„æ± 
			for _, p := range m.pools {
				p.Stop()
			}
			return fmt.Errorf("create virtual pool %q: %w", poolCfg.Name, err)
		}

		if err := pool.Start(); err != nil {
			// å…³é—­å·²å¯åŠ¨çš„æ± 
			for _, p := range m.pools {
				p.Stop()
			}
			return fmt.Errorf("start virtual pool %q: %w", poolCfg.Name, err)
		}

		m.pools[poolCfg.Name] = pool
		// è·å–åŒ¹é…çš„èŠ‚ç‚¹æ•°é‡
		nodeCount := len(pool.GetMatchingNodes())
		logger.Infof("âœ… Virtual pool %q started on %s:%d (strategy: %s, nodes: %d)",
			poolCfg.Name, poolCfg.Address, poolCfg.Port, poolCfg.Strategy, nodeCount)
	}

	return nil
}

// Stop åœæ­¢æ‰€æœ‰è™šæ‹Ÿæ± 
func (m *Manager) Stop() {
	m.cancel()

	m.mu.Lock()
	defer m.mu.Unlock()

	for name, pool := range m.pools {
		pool.Stop()
		logger.Infof("ğŸ›‘ Virtual pool %q stopped", name)
	}
	m.pools = make(map[string]*VirtualPool)
}

// GetPool è·å–æŒ‡å®šåç§°çš„è™šæ‹Ÿæ± 
// è¿”å› monitor.VirtualPoolInstance æ¥å£ä»¥æ»¡è¶³ monitor.VirtualPoolManager æ¥å£
func (m *Manager) GetPool(name string) monitor.VirtualPoolInstance {
	m.mu.RLock()
	defer m.mu.RUnlock()
	pool := m.pools[name]
	if pool == nil {
		return nil
	}
	return pool
}

// GetAllPools è·å–æ‰€æœ‰è™šæ‹Ÿæ± 
func (m *Manager) GetAllPools() []*VirtualPool {
	m.mu.RLock()
	defer m.mu.RUnlock()

	pools := make([]*VirtualPool, 0, len(m.pools))
	for _, pool := range m.pools {
		pools = append(pools, pool)
	}
	return pools
}

// Status è·å–æ‰€æœ‰è™šæ‹Ÿæ± çš„çŠ¶æ€
func (m *Manager) Status() []monitor.VirtualPoolStatus {
	m.mu.RLock()
	defer m.mu.RUnlock()

	statuses := make([]monitor.VirtualPoolStatus, 0, len(m.pools))
	for _, pool := range m.pools {
		s := pool.Status()
		statuses = append(statuses, monitor.VirtualPoolStatus{
			Name:         s.Name,
			Regular:      s.Regular,
			Address:      s.Address,
			Port:         s.Port,
			Strategy:     s.Strategy,
			MaxLatencyMs: s.MaxLatencyMs,
			NodeCount:    s.NodeCount,
			Running:      s.Running,
		})
	}
	return statuses
}

// PoolStatus è™šæ‹Ÿæ± çŠ¶æ€
type PoolStatus struct {
	Name         string `json:"name"`          // æ± åç§°
	Regular      string `json:"regular"`       // æ­£åˆ™è¡¨è¾¾å¼
	Address      string `json:"address"`       // ç›‘å¬åœ°å€
	Port         uint16 `json:"port"`          // ç›‘å¬ç«¯å£
	Strategy     string `json:"strategy"`      // è´Ÿè½½å‡è¡¡ç­–ç•¥
	MaxLatencyMs int    `json:"max_latency_ms"` // æœ€å¤§å»¶è¿Ÿé˜ˆå€¼
	NodeCount    int    `json:"node_count"`    // åŒ¹é…çš„èŠ‚ç‚¹æ•°é‡
	Running      bool   `json:"running"`       // æ˜¯å¦è¿è¡Œä¸­
}
